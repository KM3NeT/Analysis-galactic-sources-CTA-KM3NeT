{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the CTA data sets\n",
    "\n",
    "In this notebook, the IRFs of CTA are read and MapDatasets created for a given source. One can store the pseudodatasets to disk (will be written in /data/cta) by adjusting the `analysis_config.yml` (default: True).\n",
    "\n",
    "You can plot the outcome with Plot CTA datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import astropy.units as u\n",
    "\n",
    "from gammapy.datasets import MapDataset\n",
    "from gammapy.data import Observation\n",
    "from gammapy.maps import WcsGeom, MapAxis\n",
    "from gammapy.makers import MapDatasetMaker, SafeMaskMaker\n",
    "from gammapy.irf import load_cta_irfs\n",
    "\n",
    "from os import path\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from configure_analysis import AnalysisConfig\n",
    "analysisconfig = AnalysisConfig()\n",
    "\n",
    "from flux_utils import SourceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for pseudo datasets\n",
    "\n",
    "With the IRFs and input models in hand, we generate 100 pseudo data sets for each source and instrument, both for the PD and IC model. For the CTA data sets we use an analysis geometry with 16 energy bins per decade between 0.1 TeV and 154 TeV and spatial bins of $0.02^\\circ \\times 0.02^\\circ$. For each pseudo data set, we assume a total observation time of 200 hours, split equally between four pointing positions with $1^\\circ$ offset with respect to the source position. The predicted number of source and background events are summed for each pixel and Poisson-distributed random counts are drawn based on those values. \n",
    "\n",
    "For this purpose we load publicly available CTA IRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irfs = load_cta_irfs(analysisconfig.get_file(\"cta/irfs/irf_file_new_CTA.fits\"))\n",
    "irfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen CTA IRF consists of four standard parts:\n",
    "- Effective Area (`aeff`)\n",
    "- Energy Dispertion (`edisp`)\n",
    "- Point Spread Function (`psf`)\n",
    "- Background (`bkg`)\n",
    "\n",
    "Each of these can be easily depicted using the built-in `peek` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    irfs[\"aeff\"].peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The source can be set in the analysis_config.yml file\n",
    "source_name = analysisconfig.get_source()\n",
    "\n",
    "# default flux type is PD\n",
    "model = SourceModel(sourcename=source_name)\n",
    "src_pos = model.get_sourceposition\n",
    "print(\"Working on source\", source_name, \"at position\", src_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get the sky coordinates, generate the pointings and define the map geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining map geometry for binned simulation\n",
    "e_edges = np.logspace(\n",
    "    analysisconfig.get_value(\"emin\", \"cta_datasets\"), # logarithmic, in TeV\n",
    "    analysisconfig.get_value(\"emax\", \"cta_datasets\"), # bkg not properly defined above ~154 TeV \n",
    "    analysisconfig.get_value(\"nebin\", \"cta_datasets\")) * u.TeV\n",
    "energy_reco_axis = MapAxis.from_edges(e_edges, unit=\"TeV\", name=\"energy\", interp=\"log\")\n",
    "\n",
    "geom = WcsGeom.create(\n",
    "    skydir=src_pos,\n",
    "    binsz=analysisconfig.get_value(\"binwidth\", \"cta_datasets\"),\n",
    "    width=(6, 6),\n",
    "    frame=analysisconfig.get_value(\"frame\", \"cta_datasets\"),\n",
    "    axes=[energy_reco_axis],\n",
    ")\n",
    "\n",
    "# 16 bins/decade is enough also for the true energy axis\n",
    "energy_true_axis = MapAxis.from_edges(\n",
    "    e_edges, unit=\"TeV\", name=\"energy_true\", interp=\"log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create 4 observations for the 4 pointing positions, each with 1/4 of the total live time (this is not realistic, but does not matter since observations are stacked in the next step).\n",
    "Generation of the data set might take about 1min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 4 symmetric pointings each with 1deg offset from the source position\n",
    "pointings = src_pos.directional_offset_by(\n",
    "    analysisconfig.get_value(\"pointings\", \"cta_datasets\") * u.deg, \n",
    "    analysisconfig.get_value(\"offset\", \"cta_datasets\") * u.deg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating datasets\n",
    "stacked_dataset = MapDataset.create(\n",
    "    geom, name=\"CTA-dataset-{}\".format(source_name), energy_axis_true=energy_true_axis\n",
    ")\n",
    "dataset_maker = MapDatasetMaker(selection=[\"exposure\", \"background\", \"psf\", \"edisp\"])\n",
    "maker_safe_mask = SafeMaskMaker(methods=[\"offset-max\"], offset_max=4.0 * u.deg)\n",
    "livetime = analysisconfig.get_value(\"livetime\", \"cta_datasets\")  * u.h\n",
    "\n",
    "count = 0\n",
    "for pointing in pointings:\n",
    "    print (\"Working on pointing\", pointing)\n",
    "    obs = Observation.create(\n",
    "        pointing=pointing, \n",
    "        livetime=livetime/4, \n",
    "        irfs=irfs)\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        dataset = dataset_maker.run(stacked_dataset.copy(name=\"P{}\".format(count)), obs)\n",
    "    dataset = maker_safe_mask.run(dataset, obs)\n",
    "\n",
    "    # in case the background model contains infinites\n",
    "    assert np.isfinite(dataset.background_model.map.data[dataset.mask_safe.data]).all()\n",
    "    dataset.background_model.map.data[~dataset.mask_safe.data] = 0.0\n",
    "\n",
    "    # stack the datasets\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        stacked_dataset.stack(dataset)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data set is not included in the repo because of its size, but can be written to disk.\n",
    "if analysisconfig.get_value(\"write_CTA_pseudodata\", \"io\"):\n",
    "    outfilename = analysisconfig.get_file(\n",
    "        \"cta/pseudodata/CTA_{}_{}{}_p4.fits.gz\".format(\n",
    "            source_name, int(livetime.value), livetime.unit)\n",
    "    )\n",
    "    stacked_dataset.write(outfilename, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "km3net_cta",
   "language": "python",
   "name": "km3net_cta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
